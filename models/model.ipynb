{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4df58639-76e8-4770-a41f-de7f22e05a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchsummary in c:\\users\\sk reshma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: torch in c:\\users\\sk reshma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\sk reshma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: opendatasets in c:\\users\\sk reshma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.1.22)\n",
      "Requirement already satisfied: kaggle in c:\\users\\sk reshma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.7.4.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\sk reshma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\sk reshma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\sk reshma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sk reshma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\sk reshma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\sk reshma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\sk reshma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\sk reshma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\sk reshma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sk reshma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from opendatasets) (4.67.1)\n",
      "Requirement already satisfied: click in c:\\users\\sk reshma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from opendatasets) (8.1.8)\n",
      "Requirement already satisfied: bleach in c:\\users\\sk reshma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kaggle) (6.2.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in c:\\users\\sk reshma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kaggle) (2024.12.14)\n",
      "Requirement already satisfied: charset-normalizer in c:\\users\\sk reshma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kaggle) (3.4.1)\n",
      "Requirement already satisfied: idna in c:\\users\\sk reshma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kaggle) (3.10)\n",
      "Requirement already satisfied: protobuf in c:\\users\\sk reshma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kaggle) (4.25.5)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\sk reshma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kaggle) (2.9.0.post0)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\sk reshma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: requests in c:\\users\\sk reshma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kaggle) (2.32.3)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in c:\\users\\sk reshma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kaggle) (75.8.0)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\sk reshma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kaggle) (1.17.0)\n",
      "Requirement already satisfied: text-unidecode in c:\\users\\sk reshma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kaggle) (1.3)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in c:\\users\\sk reshma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kaggle) (2.3.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\sk reshma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kaggle) (0.5.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\sk reshma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from click->opendatasets) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sk reshma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchsummary torch torchvision opendatasets kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e59526f-32a8-4cce-913f-b598cd74fdd0",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (3760069520.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    pip show torch\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "pip show torch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145fe164-0987-4535-aa50-39ff685bca3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import opendatasets as od"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd9c52e-c3ba-44f9-b3c5-cd5322a1fc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595d4ff5-1cac-40da-8e3a-4469fe5e7314",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1f475a-e606-4dc8-b661-07b9a2d04227",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96014177-02ec-4119-82bc-68b83aa37785",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os                       # for working with files\n",
    "import numpy as np              # for numerical computationss\n",
    "import pandas as pd             # for working with dataframes\n",
    "import torch                    # Pytorch module \n",
    "import matplotlib.pyplot as plt # for plotting informations on graph and images using tensors\n",
    "import torch.nn as nn           # for creating  neural networks\n",
    "from torch.utils.data import DataLoader # for dataloaders \n",
    "from PIL import Image           # for checking images\n",
    "import torch.nn.functional as F # for functions for calculating loss\n",
    "import torchvision.transforms as transforms   # for transforming images into tensors \n",
    "from torchvision.utils import make_grid       # for data checking\n",
    "from torchvision.datasets import ImageFolder  # for working with classes and images\n",
    "from torchsummary import summary              # for getting the summary of our model\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bd9b15-9ae7-4dc8-85b1-07c7609483bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)\"\n",
    "train_dir = data_dir + \"/train\"\n",
    "valid_dir = data_dir + \"/valid\"\n",
    "diseases = os.listdir(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf17d1c-8963-44d7-9ab2-e70e09ee7d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing the disease names\n",
    "print(diseases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41fb3e7-473b-4c8a-8460-b22952ed1c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total disease classes are: {}\".format(len(diseases)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc9f863-27a8-40f0-a83c-378432d1abb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plants = []\n",
    "NumberOfDiseases = 0\n",
    "for plant in diseases:\n",
    "    if plant.split('___')[0] not in plants:\n",
    "        plants.append(plant.split('___')[0])\n",
    "    if plant.split('___')[1] != 'healthy':\n",
    "        NumberOfDiseases += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b428b31-e92e-446c-b532-21f14f19923e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique plants in the dataset\n",
    "print(f\"Unique Plants are: \\n{plants}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7687dd93-eda5-4a9a-abd0-96865a416cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of unique plants\n",
    "print(\"Number of plants: {}\".format(len(plants)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f87b208-938d-454c-ae60-010f70c30c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of unique diseases\n",
    "print(\"Number of diseases: {}\".format(NumberOfDiseases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f16c50-f500-40c6-811b-4be32cca35a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of images for each disease\n",
    "nums = {}\n",
    "for disease in diseases:\n",
    "    nums[disease] = len(os.listdir(train_dir + '/' + disease))\n",
    "    \n",
    "# converting the nums dictionary to pandas dataframe passing index as plant name and number of images as column\n",
    "\n",
    "img_per_class = pd.DataFrame(nums.values(), index=nums.keys(), columns=[\"no. of images\"])\n",
    "img_per_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622d8bd0-a6f7-4599-b1dd-65cbab7df1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting number of images available for each disease\n",
    "index = [n for n in range(38)]\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.bar(index, [n for n in nums.values()], width=0.3)\n",
    "plt.xlabel('Plants/Diseases', fontsize=10)\n",
    "plt.ylabel('No of images available', fontsize=10)\n",
    "plt.xticks(index, diseases, fontsize=5, rotation=90)\n",
    "plt.title('Images per each class of plant disease')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0320a49c-933d-4b34-bc5e-1a8f272b88c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 0\n",
    "for value in nums.values():\n",
    "    n_train += value\n",
    "print(f\"There are {n_train} images for training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11f54e7-5e05-41a8-aee6-2007b0e04ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    " #datasets for validation and training\n",
    "train = ImageFolder(train_dir, transform=transforms.ToTensor())\n",
    "valid = ImageFolder(valid_dir, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2787624-3e28-4a22-ba42-0e7b8b16fc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = train[0]\n",
    "print(img.shape, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed280968-bb20-4a8e-be4f-a9ec35c43a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of classes in train set\n",
    "len(train.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5e264c-575b-43f1-b67c-83d4a2e622fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for checking some images from training dataset\n",
    "def show_image(image, label):\n",
    "    print(\"Label :\" + train.classes[label] + \"(\" + str(label) + \")\")\n",
    "    plt.imshow(image.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa77aa2-dd2b-47b7-872a-34f926af3d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(*train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c64d0b2-16ed-46ad-be45-595daddef8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(*train[70000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e80a2ec-599f-414c-995e-aaf7007a22b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(*train[30000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527ae60b-ea6a-4891-a7a6-20cb5881f01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the seed value\n",
    "random_seed = 7\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b802ad1b-5284-4030-b301-c71c4e77ce41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the batch size\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e283e896-6d0e-4c3a-b814-925ff7aa1d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoaders for training and validation\n",
    "train_dl = DataLoader(train, batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "valid_dl = DataLoader(valid, batch_size, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dbe03d-dd89-4cab-9055-6293498d9c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to show a batch of training instances\n",
    "def show_batch(data):\n",
    "    for images, labels in data:\n",
    "        fig, ax = plt.subplots(figsize=(30, 30))\n",
    "        ax.set_xticks([]); ax.set_yticks([])\n",
    "        ax.imshow(make_grid(images, nrow=8).permute(1, 2, 0))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea71f242-80f8-453e-8e59-4a94c7e24b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Images for first batch of training\n",
    "show_batch(train_dl) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712d4d4c-7e79-4a8d-bf7c-dd5478741182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for moving data into GPU (if available)\n",
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available:\n",
    "        return torch.device(\"cuda\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "# for moving data to device (CPU or GPU)\n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "# for loading in the device (GPU if available else CPU)\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl:\n",
    "            yield to_device(b, self.device)\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a8f388-c3ab-4f6c-bbd8-ef155636b398",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea03ee44-e666-497b-b436-5f520a2db1cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DeviceDataLoader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Moving data into GPU\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m train_dl \u001b[38;5;241m=\u001b[39m \u001b[43mDeviceDataLoader\u001b[49m(train_dl, device)\n\u001b[0;32m      3\u001b[0m valid_dl \u001b[38;5;241m=\u001b[39m DeviceDataLoader(valid_dl, device)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DeviceDataLoader' is not defined"
     ]
    }
   ],
   "source": [
    "# Moving data into GPU\n",
    "train_dl = DeviceDataLoader(train_dl, device)\n",
    "valid_dl = DeviceDataLoader(valid_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad92295-5198-4741-9459-56d46856e5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleResidualBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.conv2(out)\n",
    "        return self.relu2(out) + x # ReLU can be applied before or after adding the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64973c0a-a2b7-4c73-a31e-74e363dc4d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for calculating the accuracy\n",
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "\n",
    "# base class for the model\n",
    "class ImageClassificationBase(nn.Module):\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch\n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch\n",
    "        out = self(images)                   # Generate prediction\n",
    "        loss = F.cross_entropy(out, labels)  # Calculate loss\n",
    "        acc = accuracy(out, labels)          # Calculate accuracy\n",
    "        return {\"val_loss\": loss.detach(), \"val_accuracy\": acc}\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x[\"val_loss\"] for x in outputs]\n",
    "        batch_accuracy = [x[\"val_accuracy\"] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()       # Combine loss  \n",
    "        epoch_accuracy = torch.stack(batch_accuracy).mean()\n",
    "        return {\"val_loss\": epoch_loss, \"val_accuracy\": epoch_accuracy} # Combine accuracies\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_accuracy']))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b760ad5-19d2-43ff-8827-6bd292421b71",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ImageClassificationBase' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 14\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m nn\u001b[38;5;241m.\u001b[39mSequential(\u001b[38;5;241m*\u001b[39mlayers)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# resnet architecture \u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mResNet9\u001b[39;00m(\u001b[43mImageClassificationBase\u001b[49m):\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, in_channels, num_diseases):\n\u001b[0;32m     16\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ImageClassificationBase' is not defined"
     ]
    }
   ],
   "source": [
    "# Architecture for training\n",
    "\n",
    "# convolution block with BatchNormalization\n",
    "def ConvBlock(in_channels, out_channels, pool=False):\n",
    "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "             nn.BatchNorm2d(out_channels),\n",
    "             nn.ReLU(inplace=True)]\n",
    "    if pool:\n",
    "        layers.append(nn.MaxPool2d(4))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "# resnet architecture \n",
    "class ResNet9(ImageClassificationBase):\n",
    "    def __init__(self, in_channels, num_diseases):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = ConvBlock(in_channels, 64)\n",
    "        self.conv2 = ConvBlock(64, 128, pool=True) # out_dim : 128 x 64 x 64 \n",
    "        self.res1 = nn.Sequential(ConvBlock(128, 128), ConvBlock(128, 128))\n",
    "        self.conv3 = ConvBlock(128, 256, pool=True) # out_dim : 256 x 16 x 16\n",
    "        self.conv4 = ConvBlock(256, 512, pool=True) # out_dim : 512 x 4 x 44\n",
    "        self.res2 = nn.Sequential(ConvBlock(512, 512), ConvBlock(512, 512))\n",
    "        \n",
    "        self.classifier = nn.Sequential(nn.MaxPool2d(4),\n",
    "                                       nn.Flatten(),\n",
    "                                       nn.Linear(512, num_diseases))\n",
    "    def forward(self, xb): # xb is the loaded batch\n",
    "        out = self.conv1(xb)\n",
    "        out = self.conv2(out)\n",
    "        out = self.res1(out) + out\n",
    "        out = self.conv3(out)\n",
    "        out = self.conv4(out)\n",
    "        out = self.res2(out) + out\n",
    "        out = self.classifier(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b3ea438-3b4e-42e3-bf54-bed351f65fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: False\n",
      "No CUDA-compatible GPU found.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "\n",
    "# Check GPU details\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"No CUDA-compatible GPU found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0365864b-00b7-4466-8a3d-277fda6a82ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: False\n",
      "Torch Version: 2.6.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"Torch Version:\", torch.__version__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20271a82-aaad-4396-b29c-9fccc7c6427f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Version: 2.6.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"Torch Version:\", torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa505723-539f-4f86-bb8f-1bfa8ea2d290",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Disease Detection",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
